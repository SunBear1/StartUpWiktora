{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":17947,"databundleVersionId":896432,"sourceType":"competition"}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ukaszniedwiadek/food101-exodia?scriptVersionId=182605175\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/ukaszniedwiadek/food101-exodia?scriptVersionId=178897214\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/ukaszniedwiadek/food101-exodia?scriptVersionId=177471599\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"cell_type":"markdown","source":"Importing libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n\nimport torch\nimport os\nimport csv\nimport cv2\nfrom PIL import Image\nfrom torchvision import transforms\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nimport timm\nfrom tqdm.notebook import tqdm\nfrom timeit import default_timer as timer\nimport torch.nn as nn\nimport time\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T16:43:28.847078Z","iopub.execute_input":"2024-06-10T16:43:28.847353Z","iopub.status.idle":"2024-06-10T16:43:43.99062Z","shell.execute_reply.started":"2024-06-10T16:43:28.847326Z","shell.execute_reply":"2024-06-10T16:43:43.989861Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \nprint(f'Using {device} device')","metadata":{"execution":{"iopub.status.busy":"2024-06-10T16:43:43.992051Z","iopub.execute_input":"2024-06-10T16:43:43.992289Z","iopub.status.idle":"2024-06-10T16:43:44.052358Z","shell.execute_reply.started":"2024-06-10T16:43:43.992267Z","shell.execute_reply":"2024-06-10T16:43:44.051463Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Using cuda device\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Defining Classes and functions","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, df, data_root, transforms=None, give_label=True):\n        \"\"\"Performed only once when the Dataset object is instantiated.\n        give_label should be False for test data\n        \"\"\" \n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.data_root = data_root\n        self.transforms = transforms\n        self.give_label = give_label\n        \n        if give_label == True:\n            self.df['label'] = self.df['label'].astype(int)\n            self.labels = self.df['label'].values\n\n    def __len__(self):\n        \"\"\"Function to return the number of records in the dataset\n        \"\"\" \n        return self.df.shape[0]\n    \n    def __getitem__(self, index):\n        \"\"\"Function to return samples corresponding to a given index from a dataset\n        \"\"\" \n        # get labels\n        if self.give_label:\n            target = self.labels[index]\n            target = torch.tensor(target)\n\n        # Load images\n        img = Image.open(f'{self.data_root}/{self.df.loc[index][\"image_id\"]}.jpg').convert(\"RGB\")\n        #img  = load_img(f'{self.data_root}/{self.df.loc[index][\"image_id\"]}.jpg').astype(np.float32)\n        # img /= 255.0 # Normalization\n\n        # Transform images\n        if self.transforms:\n            img = self.transforms(img)\n\n        if self.give_label == True:\n            return img, target\n        else:\n            return img\n\n\ndef load_img(path):\n    img = Image.open(PATH_TRAINING + category + \"\\\\\" + imgPath).convert(\"RGB\")\n    img_bgr = cv2.imread(path)\n    img_rgb = img_bgr[:, :, ::-1]\n    return img_rgb\n\n\ndef get_labels(path, give_label):\n    list_id = []\n    list_label = []\n    with open(path, mode ='r')as file:\n        csvFile = csv.reader(file)\n        for lines in csvFile:\n            list_id.append(lines[0])\n            if give_label:\n                list_label.append(lines[1])\n    list_id.pop(0)\n    if give_label:\n        list_label.pop(0)\n        return list_id, list_label\n    return list_id","metadata":{"execution":{"iopub.status.busy":"2024-06-10T16:43:48.12589Z","iopub.execute_input":"2024-06-10T16:43:48.126862Z","iopub.status.idle":"2024-06-10T16:43:48.14372Z","shell.execute_reply.started":"2024-06-10T16:43:48.126818Z","shell.execute_reply":"2024-06-10T16:43:48.142318Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Loading the dataset","metadata":{}},{"cell_type":"code","source":"main_dir = \"/kaggle/input/dat18seefood\"\nbatch_size = 32\nimage_size = 256\n\n\nitems = os.listdir(main_dir)\ntrain_id = []\ntrain_label = []\n\ntest_id = []\ntest_label = []\n\nfor item in items:\n    if item == \"train.csv\":\n        path = os.path.join(main_dir, item)\n        train_id, train_label = get_labels(path, give_label=True)\n    if item == \"test.csv\":\n        test_id = get_labels(path, give_label=False)\n        \n\n\nX_train, X_val, y_train, y_val = train_test_split(train_id, train_label, stratify=train_label, test_size=0.20, random_state=42)\nprint(f\"[DEBUG] Number of samples in validation set is: {len(X_val)}\")\nprint(f\"[DEBUG] Number of samples in train set is: {len(X_train)}\")\ndf_train = pd.DataFrame({\n    'image_id': X_train,\n    'label': y_train\n})\n\ndf_val = pd.DataFrame({\n    'image_id': X_val,\n    'label': y_val\n})\n\ndf_test = pd.DataFrame({\n    'image_id': test_id,\n})\n\ndf_labels = pd.read_csv(main_dir + '/labelnames.csv')\nprint(f\"[INFO] Loaded dataframe of dataset with ID's and labels\\n {df_labels}\")\nprint(f\"[DEBUG] Number of samples for each class in train set {df_train['label'].value_counts()}\")\nprint(f\"[DEBUG] Number of samples for each class in validation set {df_val['label'].value_counts()}\")\nprint(f\"[DEBUG] Number of samples for each class in test set {df_test['image_id'].value_counts()}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T16:43:50.212699Z","iopub.execute_input":"2024-06-10T16:43:50.213062Z","iopub.status.idle":"2024-06-10T16:43:50.570725Z","shell.execute_reply.started":"2024-06-10T16:43:50.213033Z","shell.execute_reply":"2024-06-10T16:43:50.569746Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[DEBUG] Number of samples in validation set is: 15150\n[DEBUG] Number of samples in train set is: 60600\n[INFO] Loaded dataframe of dataset with ID's and labels\n      label       labelname\n0        0       Apple pie\n1        1  Baby back ribs\n2        2         Baklava\n3        3  Beef carpaccio\n4        4    Beef tartare\n..     ...             ...\n96      96           Tacos\n97      97        Takoyaki\n98      98        Tiramisu\n99      99    Tuna tartare\n100    100         Waffles\n\n[101 rows x 2 columns]\n[DEBUG] Number of samples for each class in train set label\n53    600\n8     600\n56    600\n11    600\n70    600\n     ... \n62    600\n21    600\n19    600\n13    600\n38    600\nName: count, Length: 101, dtype: int64\n[DEBUG] Number of samples for each class in validation set label\n8     150\n45    150\n68    150\n67    150\n48    150\n     ... \n27    150\n38    150\n16    150\n10    150\n69    150\nName: count, Length: 101, dtype: int64\n[DEBUG] Number of samples for each class in test set image_id\ntrain999047     1\ntrain1005649    1\ntrain1014775    1\ntrain1026328    1\ntrain1028787    1\n               ..\ntrain1074856    1\ntrain1074942    1\ntrain1076891    1\ntrain1077610    1\ntrain1077964    1\nName: count, Length: 75750, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Augment the dataset","metadata":{}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.RandomRotation(45),\n    transforms.RandomResizedCrop(image_size, scale=(0.7, 1.0)),\n    transforms.RandomHorizontalFlip(0.2),\n    transforms.RandomVerticalFlip(0.2),\n    transforms.RandomAffine(degrees=0, shear=0.25),\n    transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.ToTensor(),\n])\n\ntrain_dataset = CustomDataset(df_train, main_dir+\"/train/\",transforms=train_transform,give_label=True)\nval_dataset = CustomDataset(df_val, main_dir+\"/train/\",transforms=val_transform,give_label=True)\ntest_dataset = CustomDataset(df_test, main_dir+\"/test/\",transforms=test_transform,give_label=False)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n#it = iter(train_loader)\n#first = next(it)\n# second = next(it)\ni=0\nprint(len(train_loader))\nfor images, labels in train_loader:\n    print(f\"Image on idx {i} {images.shape}\")\n    print(f\"Label on idx {i} {labels.shape}\")\n    i+=1\n    if i==3:\n        break","metadata":{"execution":{"iopub.status.busy":"2024-06-10T16:43:53.412817Z","iopub.execute_input":"2024-06-10T16:43:53.413731Z","iopub.status.idle":"2024-06-10T16:43:55.068338Z","shell.execute_reply.started":"2024-06-10T16:43:53.413696Z","shell.execute_reply":"2024-06-10T16:43:55.06731Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"1894\nImage on idx 0 torch.Size([32, 3, 256, 256])\nLabel on idx 0 torch.Size([32])\nImage on idx 1 torch.Size([32, 3, 256, 256])\nLabel on idx 1 torch.Size([32])\nImage on idx 2 torch.Size([32, 3, 256, 256])\nLabel on idx 2 torch.Size([32])\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# model = torch.hub.load('hankyul2/EfficientNetV2-pytorch', 'efficientnet_v2_s', pretrained=True, nclass=100)\n\n# epochs_no_improve = 0\n# valid_loss_min = np.Inf\n# max_epochs_stop = 3\n\n# valid_max_acc = 0\n# history = []\n# overall_start = timer()\n# learing_rate = 0.001\n\n# # Load model, loss function, and optimizing algorithm\n# model = model.to(device)\n# loss_fn = nn.CrossEntropyLoss().to(device)\n# optimizer = torch.optim.Adam(model.parameters(), lr=learing_rate)\n# history = []\n\n# # Start training\n# epochs = 10\n# for epoch in range(epochs):\n#     time_start = time.time()\n#     print(f'==========Epoch {epoch+1} Start Training==========')\n#     model.train()\n\n#     train_loss = 0.0\n#     valid_loss = 0.0\n\n#     train_acc = 0\n#     valid_acc = 0\n\n#     start = timer()\n#     pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n#     for step, (img, label) in pbar:\n#         img = img.to(device).float()\n#         label = label.to(device).long()\n\n#         output = model(img)\n#         loss = loss_fn(output, label)\n\n#         optimizer.zero_grad()\n#         loss.backward()\n#         optimizer.step()\n\n#         train_loss += loss.item() * img.size(0)\n#         # Calculate accuracy by finding max log probability\n#         _, pred = torch.max(output, dim=1)\n#         correct_tensor = pred.eq(label.data.view_as(pred))\n#         # Need to convert correct tensor from int to float to average\n#         accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n#         # Multiply average accuracy times the number of examples in batch\n#         train_acc += accuracy.item() * img.size(0)\n\n#         # Track training progress\n#         print(f'Epoch: {epoch}\\t{100 * (step + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',end='\\r')\n\n\n#     model.epochs += 1\n#     with torch.no_grad():\n#         model.eval()\n#         pbar = tqdm(enumerate(valid_loader), total=len(valid_loader))\n#         for step, (img, label) in pbar:\n#             img = img.to(device).float()\n#             label = label.to(device).long()\n\n#             output = model(img)\n\n#             loss = loss_fn(output, label)\n\n#             valid_loss += loss.item() * data.size(0)\n#             # Calculate validation accuracy\n#             _, pred = torch.max(output, dim=1)\n#             correct_tensor = pred.eq(label.data.view_as(pred))\n#             accuracy = torch.mean(\n#                 correct_tensor.type(torch.FloatTensor))\n#             # Multiply average accuracy times the number of examples\n#             valid_acc += accuracy.item() * data.size(0)\n\n\n#     # Calculate average loss      \n#     train_loss = train_loss / len(train_loader.dataset)\n#     valid_loss = valid_loss / len(valid_loader.dataset)\n\n#     # Calculate average accuracy\n#     train_acc = train_acc / len(train_loader.dataset)\n#     valid_acc = valid_acc / len(valid_loader.dataset)\n\n#     history.append([train_loss, valid_loss, train_acc, valid_acc])\n#     print(f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}')\n#     print(f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%')\n\n#     if valid_loss < valid_loss_min:\n#         # Save model\n#         torch.save(model.state_dict(), save_file_name)\n#         # Track improvement\n#         epochs_no_improve = 0\n#         valid_loss_min = valid_loss\n#         valid_best_acc = valid_acc\n#         best_epoch = epoch\n#     else:\n#         epochs_no_improve += 1\n#         # Trigger early stopping\n#         if epochs_no_improve >= max_epochs_stop:\n#             print(\n#                 f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n#             )\n#             total_time = timer() - overall_start\n#             print(\n#                 f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n#             )\n\n#             # Load the best state dict\n#             #model.load_state_dict(torch.load(save_file_name))\n#             # Attach the optimizer\n#             model.optimizer = optimizer\n\n#             # Format history\n#             history = pd.DataFrame(\n#                 history,\n#                 columns=[\n#                     'train_loss', 'valid_loss', 'train_acc', 'valid_acc'\n#                 ])\n#             break\n\n#     # print results from this epoch\n#     exec_t = int((time.time() - time_start)/60)\n#     print(\n#         f'Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} / Exec time {exec_t} min\\n'\n#     )\n\n# # Attach the optimizer\n# model.optimizer = optimizer\n# # Record overall time and print out stats\n# total_time = timer() - overall_start\n# print(\n#     f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n# )\n# print(\n#     f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\n# )\n# # Format history\n# history = pd.DataFrame(\n#     history,\n#     columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n\n\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"a8da46ad-e5cf-4f3b-ba40-c97c26e420e9","_cell_guid":"d7b14f16-e381-4eeb-974c-919f228bc70b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-10T16:44:28.030949Z","iopub.execute_input":"2024-06-10T16:44:28.031789Z","iopub.status.idle":"2024-06-10T16:44:37.588411Z","shell.execute_reply.started":"2024-06-10T16:44:28.031757Z","shell.execute_reply":"2024-06-10T16:44:37.587104Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/hankyul2_EfficientNetV2-pytorch_main\n","output_type":"stream"},{"name":"stdout","text":"==========Epoch 1 Start Training==========\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1894 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39893c93b02a4120ae8a51cf739d69d5"}},"metadata":{}},{"name":"stdout","text":"Epoch: 0\t0.32% complete. 7.58 seconds elapsed in epoch.\r","output_type":"stream"},{"name":"stderr","text":"/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [31,0,0] Assertion `t >= 0 && t < n_classes` failed.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output, label)\n\u001b[1;32m     40\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 41\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     44\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m img\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:244\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    235\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    236\u001b[0m     (inputs,)\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[1;32m    241\u001b[0m )\n\u001b[1;32m    243\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[0;32m--> 244\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:127\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    121\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    122\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for real scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m         )\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    126\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 127\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     )\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"],"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error"}]}]}