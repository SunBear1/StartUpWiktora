{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":17947,"databundleVersionId":896432,"sourceType":"competition"}],"dockerImageVersionId":30699,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ukaszniedwiadek/food101-exodia?scriptVersionId=178383027\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/ukaszniedwiadek/food101-exodia?scriptVersionId=177471599\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n\nimport torch\nimport os\nimport csv\nimport cv2\nfrom PIL import Image\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\n\ndef load_img(path):\n    img_bgr = cv2.imread(path)\n    img_rgb = img_bgr[:, :, ::-1]\n    return img_rgb\n\n\nclass CustomDataset(Dataset):\n    def __init__(self, df, data_root, transforms=None, give_label=True):\n        \"\"\"Performed only once when the Dataset object is instantiated.\n        give_label should be False for test data\n        \"\"\" \n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.data_root = data_root\n        self.transforms = transforms\n        self.give_label = give_label\n        \n        if give_label == True:\n            self.df['label'] = self.df['label'].astype(int)\n            self.labels = self.df['label'].values\n\n    def __len__(self):\n        \"\"\"Function to return the number of records in the dataset\n        \"\"\" \n        return self.df.shape[0]\n    \n    def __getitem__(self, index):\n        \"\"\"Function to return samples corresponding to a given index from a dataset\n        \"\"\" \n        # get labels\n        if self.give_label:\n            target = self.labels[index]\n            target = torch.tensor(target)\n\n        # Load images\n        img  = load_img(f'{self.data_root}/{self.df.loc[index][\"image_id\"]}.jpg').astype(np.float32)\n        # img /= 255.0 # Normalization\n\n        # Transform images\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n\n        if self.give_label == True:\n            return img, target\n        else:\n            return img\n\ndef get_labels(path, give_label):\n    list_id = []\n    list_label = []\n    with open(path, mode ='r')as file:\n        csvFile = csv.reader(file)\n        for lines in csvFile:\n            list_id.append(lines[0])\n            if give_label:\n                list_label.append(lines[1])\n    list_id.pop(0)\n    if give_label:\n        list_label.pop(0)\n        return list_id, list_label\n    return list_id\n\nmain_dir = \"/kaggle/input/dat18seefood\"\nbatch_size = 32\nimage_size = 256\n\n\n\n\nitems = os.listdir(main_dir)\ntrain_id = []\ntrain_label = []\n\ntest_id = []\ntest_label = []\n\nfor item in items:\n    if item == \"train.csv\":\n        path = os.path.join(main_dir, item)\n        train_id, train_label = get_labels(path, give_label=True)\n    if item == \"test.csv\":\n        test_id = get_labels(path, give_label=False)\n        \n\n\nX_train, X_val, y_train, y_val = train_test_split(train_id, train_label, stratify=train_label, test_size=0.20, random_state=42)\nprint(len(X_val))\nprint(len(X_train))\ndf_train = pd.DataFrame({\n    'image_id': X_train,\n    'label': y_train\n})\n\ndf_val = pd.DataFrame({\n    'image_id': X_val,\n    'label': y_val\n})\n\ndf_test = pd.DataFrame({\n    'image_id': test_id,\n})\n\ndf = pd.read_csv(main_dir + '/labelnames.csv')\nprint(df)\n\nimage_transforms = {\n    'train':\n    A.Compose(([\n        A.Resize(image_size,image_size,p=1),\n        A.HorizontalFlip(p=0.5),\n        A.ShiftScaleRotate(p=0.5),\n        A.CoarseDropout(p=0.5),\n        ToTensorV2(p=1.0)\n    ])),\n    'valid':\n    A.Compose(([\n        A.Resize(image_size,image_size,p=1),\n        ToTensorV2(p=1.0)\n    ])),\n    'test':\n    A.Compose(([\n        A.Resize(512,512,p=1),\n        ToTensorV2(p=1.0)\n    ]))\n}\n\ntrain_dataset = CustomDataset(df_train, main_dir+\"/train/\",transforms=image_transforms[\"train\"],give_label=True)\nvalid_dataset = CustomDataset(df_val, main_dir+\"/train/\",transforms=image_transforms[\"valid\"],give_label=True)\ntest_dataset = CustomDataset(df_test, main_dir+\"/test/\",transforms=image_transforms[\"test\"],give_label=False)\n\ndataloaders = {\n    'train': DataLoader(train_dataset, batch_size=batch_size, shuffle=True),\n    'val': DataLoader(valid_dataset, batch_size=batch_size, shuffle=True),\n    'test': DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n}\ntrainiter = iter(dataloaders['train'])\nfeatures, labels = next(trainiter)\nprint(features.shape, labels.shape)\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"a8da46ad-e5cf-4f3b-ba40-c97c26e420e9","_cell_guid":"d7b14f16-e381-4eeb-974c-919f228bc70b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-18T14:08:01.18248Z","iopub.execute_input":"2024-05-18T14:08:01.18286Z","iopub.status.idle":"2024-05-18T14:08:01.99255Z","shell.execute_reply.started":"2024-05-18T14:08:01.18283Z","shell.execute_reply":"2024-05-18T14:08:01.991703Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"15150\n60600\n     label       labelname\n0        0       Apple pie\n1        1  Baby back ribs\n2        2         Baklava\n3        3  Beef carpaccio\n4        4    Beef tartare\n..     ...             ...\n96      96           Tacos\n97      97        Takoyaki\n98      98        Tiramisu\n99      99    Tuna tartare\n100    100         Waffles\n\n[101 rows x 2 columns]\ntorch.Size([32, 3, 256, 256]) torch.Size([32])\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"JD Disa zwisa\")","metadata":{"_uuid":"4d4f8678-64bc-4e25-bd67-d8b67d48e2fd","_cell_guid":"d66d892c-47f0-41a0-94a1-3b300080db01","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-17T17:28:48.235163Z","iopub.status.idle":"2024-05-17T17:28:48.23564Z","shell.execute_reply.started":"2024-05-17T17:28:48.235398Z","shell.execute_reply":"2024-05-17T17:28:48.235416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nprint(torch.cuda.is_available())","metadata":{"_uuid":"067d55dc-f77c-40c6-af52-a602c04acbc4","_cell_guid":"2cba3991-76d9-4bf2-be5b-8f11a25904c9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-13T20:03:13.875165Z","iopub.execute_input":"2024-05-13T20:03:13.875986Z","iopub.status.idle":"2024-05-13T20:03:20.7677Z","shell.execute_reply.started":"2024-05-13T20:03:13.875943Z","shell.execute_reply":"2024-05-13T20:03:20.766659Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}]}]}